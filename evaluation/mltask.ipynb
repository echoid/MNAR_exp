{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from data_loaders import *\n",
    "from missing_process.block_rules import *\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_target(dataname,y):\n",
    "    if dataname in [\"concrete_compression\",\n",
    "            \"wine_quality_white\",\"wine_quality_red\",\n",
    "            \"california\",\"yacht_hydrodynamics\"\n",
    "            ]:\n",
    "        return y,\"ML_rmse\"\n",
    "    \n",
    "    else:\n",
    "        encoder = LabelEncoder()\n",
    "        y_encoded = encoder.fit_transform(y.reshape(-1, 1))\n",
    "        return y_encoded,\"ML_f1\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "r1 = LinearRegression()\n",
    "r2 = RandomForestRegressor(n_estimators=10, random_state=1)\n",
    "r3 = KNeighborsRegressor()\n",
    "er = VotingRegressor([('lr', r1), ('rf', r2), ('r3', r3)])\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_datalist = [\n",
    "    \"banknote\",\n",
    "        \"concrete_compression\",\n",
    "            # \"wine_quality_white\",\"wine_quality_red\",\n",
    "            # \"california\",\"climate_model_crashes\",\n",
    "            # \"connectionist_bench_sonar\",\"qsar_biodegradation\",\n",
    "            # \"yeast\",\"yacht_hydrodynamics\"\n",
    "            ]\n",
    "#real_datalist = [\"yacht_hydrodynamics\"]\n",
    "\n",
    "syn_datalist = [\"syn1\"]\n",
    "\n",
    "\n",
    "missingtypelist = [\n",
    "                    \"quantile\",\n",
    "                   \"diffuse\",\n",
    "                   \"logistic\"\n",
    "                   ]\n",
    "#missingtypelist = [\"diffuse\"]\n",
    "\n",
    "seed = 1\n",
    "nfold = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_impute_data(missingtype,model_name,rule_name,dataname,fold,seed = 1):\n",
    "\n",
    "    train_impute = np.load(f'impute/{missingtype}/{dataname}/{model_name}/{rule_name}_seed-{seed}_{fold}_train.npy')\n",
    "    test_impute = np.load(f'impute/{missingtype}/{dataname}/{model_name}/{rule_name}_seed-{seed}_{fold}_test.npy')\n",
    "    return train_impute,test_impute\n",
    "\n",
    "def load_train_test(index_file,norm_values,observed_masks,label_values):  \n",
    "\n",
    "    train_index = index_file[\"train_index\"]\n",
    "    test_index = index_file[\"test_index\"]\n",
    "\n",
    "    train_values = norm_values[train_index,:]\n",
    "\n",
    "    train_masks = observed_masks[train_index,:]\n",
    "\n",
    "    test_values = norm_values[test_index,:]\n",
    "\n",
    "    test_masks = observed_masks[test_index,:]\n",
    "\n",
    "\n",
    "    train_label = label_values[train_index]\n",
    "\n",
    "    test_label = label_values[test_index]\n",
    "\n",
    "    return train_values,train_masks,train_label,test_values,test_masks,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]e:\\ANACONDA\\envs\\py3.10\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "100%|██████████| 2/2 [00:50<00:00, 25.12s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]e:\\ANACONDA\\envs\\py3.10\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.92s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]e:\\ANACONDA\\envs\\py3.10\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.24s/it]\n"
     ]
    }
   ],
   "source": [
    "datalist = real_datalist\n",
    "model_name = \"mf\"\n",
    "\n",
    "for missingtype in missingtypelist:\n",
    "    if missingtype == \"logistic\":\n",
    "        missing_rule = load_json_file(\"missing_rate.json\")\n",
    "    elif missingtype == \"diffuse\":\n",
    "        missing_rule = load_json_file(\"diffuse_ratio.json\")\n",
    "    elif missingtype == \"quantile\":\n",
    "        missing_rule = load_json_file(\"quantile_full.json\")\n",
    "\n",
    "    # load data and its mask\n",
    "    for dataname in tqdm(datalist):\n",
    "        \n",
    "        directory_path = f\"datasets/{dataname}\"\n",
    "        data = dataset_loader(dataname)    \n",
    "        norm_values = np.load(f'{directory_path}/{dataname}_norm.npy')\n",
    "        label_values, task_type = process_target(dataname,data[\"target\"])\n",
    "\n",
    "        train_eval_mean = []\n",
    "        train_eval_std = []\n",
    "        train_eval_mean_baseline = []\n",
    "        train_eval_std_baseline = []\n",
    "        \n",
    "        test_eval_mean = []\n",
    "        test_eval_std = []\n",
    "        test_eval_mean_baseline = []\n",
    "        test_eval_std_baseline = []\n",
    "\n",
    "\n",
    "        for rule_name in missing_rule:\n",
    "            observed_masks = np.load(f'{directory_path}/{missingtype}/{rule_name}.npy')\n",
    "            f = open(f'{directory_path}/split_index_cv_seed-{seed}_nfold-{nfold}.json')\n",
    "            index_file = json.load(f)\n",
    "\n",
    "            \n",
    "\n",
    "            train_eval_list = []\n",
    "            test_eval_list = []\n",
    "            train_eval_list_baseline = []\n",
    "            test_eval_list_baseline = []\n",
    "\n",
    "            for fold in index_file:\n",
    "                index = index_file[fold]\n",
    "                train_values,train_masks,train_label,test_values,test_masks,test_label = load_train_test(index,norm_values,observed_masks,label_values)\n",
    "                impute_train,impute_test  = load_impute_data(missingtype,model_name,rule_name,dataname,fold)\n",
    "\n",
    "                train_eval,test_eval = model_eval(train_label,impute_train,impute_test,test_label,task_type)\n",
    "                train_eval_baseline,test_eval_baseline = model_eval(train_label,train_values,test_values,test_label,task_type)\n",
    "\n",
    "\n",
    "                train_eval_list.append(train_eval)\n",
    "                test_eval_list.append(test_eval)\n",
    "\n",
    "                train_eval_list_baseline.append(train_eval_baseline)\n",
    "                test_eval_list_baseline.append(test_eval_baseline)\n",
    "\n",
    "            train_eval_mean.append(np.mean(train_eval_list))\n",
    "            train_eval_std.append(np.std(train_eval_list))\n",
    "            train_eval_mean_baseline.append(np.mean(train_eval_list_baseline))\n",
    "            train_eval_std_baseline.append(np.std(train_eval_list_baseline))\n",
    "\n",
    "\n",
    "\n",
    "            test_eval_mean.append(np.mean(test_eval_list))\n",
    "            test_eval_std.append(np.std(test_eval_list))\n",
    "            test_eval_mean_baseline.append(np.mean(test_eval_list_baseline))\n",
    "            test_eval_std_baseline.append(np.std(test_eval_list_baseline))\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        df = pd.DataFrame({\n",
    "        f\"train_{task_type}_mean\": train_eval_mean,\n",
    "        f\"train_{task_type}_std\":train_eval_std,\n",
    "\n",
    "\n",
    "        f\"test_{task_type}_mean\": test_eval_mean,\n",
    "        f\"test_{task_type}_std\": test_eval_std,\n",
    "\n",
    "\n",
    "        },index = [rule_name for rule_name in missing_rule])\n",
    "            \n",
    "        path = f\"results/{missingtype}/{dataname}/{model_name}\"\n",
    "        if not os.path.exists(path):\n",
    "                # If the path does not exist, create it\n",
    "            os.makedirs(path)\n",
    "            \n",
    "        df.to_csv(f'{path}/{missingtype}_{task_type}.csv')\n",
    "   \n",
    "\n",
    "                    \n",
    "        df = pd.DataFrame({\n",
    "        f\"train_{task_type}_mean\": train_eval_mean_baseline,\n",
    "        f\"train_{task_type}_std\":train_eval_std_baseline,\n",
    "\n",
    "\n",
    "        f\"test_{task_type}_mean\": test_eval_mean_baseline,\n",
    "        f\"test_{task_type}_std\": test_eval_std_baseline,\n",
    "\n",
    "\n",
    "        },index = [rule_name for rule_name in missing_rule])\n",
    "            \n",
    "        path = f\"results/{missingtype}/{dataname}/\"\n",
    "        if not os.path.exists(path):\n",
    "                # If the path does not exist, create it\n",
    "            os.makedirs(path)\n",
    "            \n",
    "        df.to_csv(f'{path}/{missingtype}_{task_type}_baseline.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(label_train,impute_train,impute_test,label_test,task_type):\n",
    "    if task_type == \"ML_rmse\":\n",
    "        er.fit(impute_train,label_train)\n",
    "        y_pred_train = er.predict(impute_train)\n",
    "        y_pred_test = er.predict(impute_test)\n",
    "\n",
    "        train_eval = mean_squared_error(label_train, y_pred_train, squared=False)\n",
    "        test_eval = mean_squared_error(label_test, y_pred_test, squared=False)\n",
    "        return train_eval,test_eval\n",
    "    else:\n",
    "        eclf.fit(impute_train,label_train)\n",
    "        y_pred_train = eclf.predict(impute_train)\n",
    "        y_pred_test = eclf.predict(impute_test)\n",
    "\n",
    "        train_eval = f1_score(label_train, y_pred_train, average='macro')\n",
    "        test_eval = f1_score(label_test, y_pred_test, average='macro')\n",
    "\n",
    "        return train_eval,test_eval\n",
    "    \n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(norm_value,impute,mask, title = None,subtitle = None):\n",
    "\n",
    "    indices = np.argsort(subtitle)[-8:]\n",
    "\n",
    "    # Sorting the indices and converting to a list\n",
    "    sorted_indices = np.sort(indices).tolist()\n",
    "\n",
    "        # Create a 4x2 grid of subplots\n",
    "    fig, axes = plt.subplots(4, 2, figsize=(12, 12))\n",
    "    axes = axes.ravel()  # Flatten the 4x2 grid for easy iteration\n",
    "\n",
    "    impute_value = impute\n",
    "    nan_mask = np.where(mask == 0, np.nan, mask)\n",
    "    masked_value_na = norm_value * nan_mask\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(len(sorted_indices)):\n",
    "        norm_column = norm_value[:, sorted_indices[i]]\n",
    "        impute_column = impute_value[:, sorted_indices[i]]\n",
    "        mask_column_na = masked_value_na[:, sorted_indices[i]]\n",
    "\n",
    "        \n",
    "        bins = np.histogram_bin_edges([norm_column, impute_column], bins='auto')\n",
    "        #data_column2 = array_list[1][i]\n",
    "        # Histogram\n",
    "        #axes[i].hist(data_column, bins=30, alpha=0.7, edgecolor='black',kde = True)\n",
    "        sns.histplot(data=norm_column, bins=bins, color='orange',alpha = 0.4, ax=axes[i], kde=True, label='Complete Data',\n",
    "                     #hatch=\"\", \n",
    "                     fill=False\n",
    "                     )\n",
    "        sns.histplot(data=mask_column_na, bins=bins, color='blue',alpha = 0.1, ax=axes[i], kde=True, label='Observed Data',\n",
    "                     #hatch=\"/\", \n",
    "                     #fill=False\n",
    "                     )\n",
    "        sns.histplot(data=impute_column, bins=bins, color='green',alpha = 0.6, ax=axes[i], kde=True, label='Imputed Data',\n",
    "                     hatch='...', \n",
    "                     fill=False\n",
    "                     )\n",
    "        axes[i].set_xlabel('Value')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        if subtitle[i]:\n",
    "            axes[i].set_title(f'Histogram for Column {sorted_indices[i]+1} RMSE: {subtitle[i]}')\n",
    "        else:\n",
    "            axes[i].set_title(f'Histogram for Column {sorted_indices[i]+1}')\n",
    "        axes[i].legend()\n",
    "\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "        # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../plot/{title}.png\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
