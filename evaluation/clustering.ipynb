{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from data_loaders import *\n",
    "from missing_process.block_rules import *\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import (\n",
    "    homogeneity_score,\n",
    "    completeness_score,\n",
    "    v_measure_score,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mutual_info_score,\n",
    "    normalized_mutual_info_score,\n",
    "    adjusted_mutual_info_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_datalist = [\n",
    "#     \"banknote\",\n",
    "#         \"concrete_compression\",\n",
    "#             \"climate_model_crashes\",\n",
    "#             \"connectionist_bench_sonar\",\"qsar_biodegradation\",\n",
    "#             \"yeast\"\n",
    "#             ]\n",
    "\n",
    "real_datalist = [\n",
    "    \"banknote\",\n",
    "        \"concrete_compression\",\n",
    "            \"wine_quality_white\",\"wine_quality_red\",\n",
    "            \"california\",\"climate_model_crashes\",\n",
    "            \"connectionist_bench_sonar\",\"qsar_biodegradation\",\n",
    "            \"yeast\",\"yacht_hydrodynamics\"\n",
    "            ]\n",
    "\n",
    "\n",
    "# except_list = [\"banknote\"\n",
    "# \"climate_model_crashes\"\n",
    "# \"connectionist_bench_sonar\"]\n",
    "\n",
    "real_datalist = [\n",
    "        \"concrete_compression\",\n",
    "            \"wine_quality_white\",\"wine_quality_red\",\n",
    "            \"california\",\n",
    "\"qsar_biodegradation\",\n",
    "            \"yeast\",\"yacht_hydrodynamics\"\n",
    "            ]\n",
    "\n",
    "missingtypelist = [\n",
    "                    \"quantile\",\n",
    "                   \"diffuse\",\n",
    "                   \"logistic\"\n",
    "                   ]\n",
    "\n",
    "seed = 1\n",
    "nfold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_impute_data(missingtype,model_name,rule_name,dataname,fold,seed = 1):\n",
    "\n",
    "    train_impute = np.load(f'impute/{missingtype}/{dataname}/{model_name}/{rule_name}_seed-{seed}_{fold}_train.npy')\n",
    "    test_impute = np.load(f'impute/{missingtype}/{dataname}/{model_name}/{rule_name}_seed-{seed}_{fold}_test.npy')\n",
    "    return train_impute,test_impute\n",
    "\n",
    "def load_train_test(index_file,norm_values,observed_masks):  \n",
    "\n",
    "    train_index = index_file[\"train_index\"]\n",
    "    test_index = index_file[\"test_index\"]\n",
    "\n",
    "    train_values = norm_values[train_index,:]\n",
    "\n",
    "    train_masks = observed_masks[train_index,:]\n",
    "\n",
    "    test_values = norm_values[test_index,:]\n",
    "\n",
    "    test_masks = observed_masks[test_index,:]\n",
    "\n",
    "\n",
    "    return train_values,train_masks,test_values,test_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillin_imputed_data(imputed,mask,original):\n",
    "    filled_data = np.where(mask == 1, original, imputed)\n",
    "    return filled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 45.00it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.32it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 23.62it/s]\n",
      "100%|██████████| 9/9 [00:24<00:00,  2.71s/it]\n",
      "100%|██████████| 9/9 [00:00<00:00, 26.54it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 27.86it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 72.00it/s]\n",
      "100%|██████████| 7/7 [00:28<00:00,  4.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# Single Model Name\n",
    "\n",
    "datalist = real_datalist\n",
    "model_name = \"tabcsdi\"\n",
    "missingtypelist = [\"logistic\"]\n",
    "for missingtype in missingtypelist:\n",
    "    if missingtype == \"logistic\":\n",
    "        missing_rule = load_json_file(\"missing_rate.json\")\n",
    "    elif missingtype == \"diffuse\":\n",
    "        missing_rule = load_json_file(\"diffuse_ratio.json\")\n",
    "    elif missingtype == \"quantile\":\n",
    "        missing_rule = load_json_file(\"quantile_full.json\")\n",
    "\n",
    "    d_v = {}\n",
    "    d_AMI = {}\n",
    "\n",
    "    # load data and its mask\n",
    "    for dataname in tqdm(datalist):\n",
    "        \n",
    "        directory_path = f\"datasets/{dataname}\"\n",
    "        data = dataset_loader(dataname)    \n",
    "        norm_values = np.load(f'{directory_path}/{dataname}_norm.npy')\n",
    "\n",
    "        # clustering = DBSCAN().fit(norm_values)\n",
    "        # #print(clustering.labels_)\n",
    "        # ncluster = len(set(clustering.labels_))\n",
    "        # if ncluster == 1:\n",
    "        #     print(dataname)\n",
    "        d_v[dataname] = []\n",
    "        d_AMI[dataname] = []\n",
    "\n",
    "        for rule_name in tqdm(missing_rule):\n",
    "            \n",
    "            observed_masks = np.load(f'{directory_path}/{missingtype}/{rule_name}.npy')\n",
    "            f = open(f'{directory_path}/split_index_cv_seed-{seed}_nfold-{nfold}.json')\n",
    "            index_file = json.load(f)\n",
    "\n",
    "            v_list = []\n",
    "            AMI_list = []\n",
    "            for fold in index_file:\n",
    "                index = index_file[fold]\n",
    "                train_values,train_masks,test_values,test_masks = load_train_test(index,norm_values,observed_masks)\n",
    "                impute_train,impute_test  = load_impute_data(missingtype,model_name,rule_name,dataname,fold)\n",
    "\n",
    "                impute_test = fillin_imputed_data(impute_test,test_masks,test_values)\n",
    "                # print(impute_test)\n",
    "                # print(test_values)\n",
    "                # print(test_masks)\n",
    "                clu_test = DBSCAN().fit(test_values).labels_\n",
    "                clu_test_imp = DBSCAN().fit(impute_test).labels_\n",
    "\n",
    "                \n",
    "                V = v_measure_score(clu_test, clu_test_imp)\n",
    "                AMI = adjusted_mutual_info_score(clu_test, clu_test_imp)\n",
    "\n",
    "                v_list.append(V)\n",
    "                AMI_list.append(AMI)\n",
    "            \n",
    "\n",
    "            d_v[dataname].append(np.mean(v_list))\n",
    "            d_AMI[dataname] .append(np.mean(AMI_list))\n",
    "\n",
    "    df_v = pd.DataFrame(d_v,index=[rule_name for rule_name in missing_rule])\n",
    "    df_AMI = pd.DataFrame(d_AMI,index=[rule_name for rule_name in missing_rule])\n",
    "\n",
    "    path = f\"clustering/{missingtype}/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    df_v.to_csv(f\"{path}/{model_name}_V.csv\")\n",
    "\n",
    "    df_AMI.to_csv(f'{path}/{model_name}_AMI.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillin_imputed_data(imputed, mask, original):\n",
    "    \"\"\"\n",
    "    Fill in missing values in the imputed dataset using the original dataset and the mask.\n",
    "    Replace NaNs in the imputed dataset with 1 when the mask indicates missing values.\n",
    "\n",
    "    Parameters:\n",
    "        imputed (numpy.ndarray): Imputed dataset with missing values.\n",
    "        mask (numpy.ndarray): Mask indicating missing values (NaNs).\n",
    "        original (numpy.ndarray): Original dataset with complete values.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: New dataset with missing values filled in.\n",
    "    \"\"\"\n",
    "    filled_data = np.where(np.isnan(mask), 1, imputed)\n",
    "    return filled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datalist = real_datalist\n",
    "model_name_list = [\"random\",\"zero\",\"Mean\",\"MF\",\"KNN\",\"MICE\",\"Missforest\",\"XGB\",\"OT\",\"Hyper\",\"GAIN\",\"notmiwae\",\"miwae\",\"tabcsdi\"]\n",
    "\n",
    "missingtypelist = [\"logistic\"]\n",
    "rule_name = 0.5\n",
    "\n",
    "def run_cluster(rule_name,model_name_list,missingtype,datalist):\n",
    "\n",
    "    d_v = {}\n",
    "    d_AMI= {}\n",
    "\n",
    "    for dataname in tqdm(datalist):\n",
    "        \n",
    "        directory_path = f\"datasets/{dataname}\"\n",
    "        data = dataset_loader(dataname)    \n",
    "        norm_values = np.load(f'{directory_path}/{dataname}_norm.npy')\n",
    "        \n",
    "        observed_masks = np.load(f'{directory_path}/{missingtype}/{rule_name}.npy')\n",
    "        f = open(f'{directory_path}/split_index_cv_seed-{seed}_nfold-{nfold}.json')\n",
    "        index_file = json.load(f)\n",
    "\n",
    "        d_v[dataname] = {}\n",
    "        d_AMI[dataname] = {}\n",
    "\n",
    "        for model_name in model_name_list:\n",
    "            d_v[dataname][model_name]=0\n",
    "            d_AMI[dataname][model_name]=0\n",
    "            # load data and its mask\n",
    "\n",
    "            v_list = []\n",
    "            AMI_list = []\n",
    "            for fold in index_file:\n",
    "                index = index_file[fold]\n",
    "                train_values,train_masks,test_values,test_masks = load_train_test(index,norm_values,observed_masks)\n",
    "                impute_train,impute_test  = load_impute_data(missingtype,model_name,rule_name,dataname,fold)\n",
    "\n",
    "                impute_test = fillin_imputed_data(impute_test,test_masks,test_values)\n",
    "                impute_test = np.nan_to_num(impute_test, nan=0)\n",
    "\n",
    "                clu_test = DBSCAN().fit(test_values).labels_\n",
    "                clu_test_imp = DBSCAN().fit(impute_test).labels_\n",
    "\n",
    "                \n",
    "                V = v_measure_score(clu_test, clu_test_imp)\n",
    "                AMI = adjusted_mutual_info_score(clu_test, clu_test_imp)\n",
    "\n",
    "                v_list.append(V)\n",
    "                AMI_list.append(AMI)\n",
    "            \n",
    "\n",
    "            d_v[dataname][model_name]=np.mean(v_list)\n",
    "            d_AMI[dataname][model_name]=np.mean(AMI_list)\n",
    "\n",
    "\n",
    "    df_v = pd.DataFrame(d_v).T\n",
    "    df_AMI = pd.DataFrame(d_AMI).T\n",
    "\n",
    "\n",
    "    path = f\"clustering/{missingtype}/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    df_v.to_csv(f\"{path}/{rule_name}_V.csv\")\n",
    "\n",
    "    df_AMI.to_csv(f'{path}/{rule_name}_AMI.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:46<00:00,  6.60s/it]\n",
      "100%|██████████| 7/7 [00:46<00:00,  6.66s/it]\n",
      "100%|██████████| 7/7 [00:48<00:00,  6.95s/it]\n",
      "100%|██████████| 7/7 [00:48<00:00,  6.92s/it]\n",
      "100%|██████████| 7/7 [00:44<00:00,  6.39s/it]\n",
      "100%|██████████| 7/7 [00:48<00:00,  6.94s/it]\n"
     ]
    }
   ],
   "source": [
    "missingtype = \"diffuse\"\n",
    "missingtype = \"logistic\"\n",
    "model_name_list = [\"random\",\"zero\",\"Mean\",\"MF\",\"KNN\",\"MICE\",\"Missforest\",\"XGB\",\"OT\",\"Hyper\",\"GAIN\",\"notmiwae\",\"miwae\",\"tabcsdi\"]\n",
    "real_datalist = [\n",
    "        \"concrete_compression\",\n",
    "            \"wine_quality_white\",\"wine_quality_red\",\n",
    "            \"california\",\n",
    "\"qsar_biodegradation\",\n",
    "            \"yeast\",\"yacht_hydrodynamics\"\n",
    "            ]\n",
    "\n",
    "for missingtype in [\"diffuse\",\"logistic\"]:\n",
    "    for rule_name in [\"0.3\",\"0.5\",\"0.7\"]:\n",
    "        run_cluster(rule_name,model_name_list,missingtype,real_datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:50<00:00,  7.16s/it]\n",
      "100%|██████████| 7/7 [00:47<00:00,  6.78s/it]\n",
      "100%|██████████| 7/7 [00:49<00:00,  7.01s/it]\n"
     ]
    }
   ],
   "source": [
    "missingtype = \"quantile\"\n",
    "for rule_name in [\"Q1_Q4_0.5\",\"Q2_Q3_0.5\",\"Q2_Q4_0.5\"]:\n",
    "    run_cluster(rule_name,model_name_list,missingtype,real_datalist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
