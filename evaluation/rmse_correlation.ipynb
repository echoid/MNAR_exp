{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "from missing_process.block_rules import *\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_datalist = [\"banknote\",\"concrete_compression\",\n",
    "            \"wine_quality_white\",\"wine_quality_red\",\n",
    "            \"california\",\"climate_model_crashes\",\n",
    "            \"connectionist_bench_sonar\",\"qsar_biodegradation\",\n",
    "            \"yeast\",\"yacht_hydrodynamics\"\n",
    "            ]\n",
    "\n",
    "#missingtypelist = [\"quantile\",\"diffuse\",\"logistic\"]\n",
    "missingtypelist = [\"logistic\"]\n",
    "\n",
    "seed = 1\n",
    "nfold = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_origin_data(missingtypelist,datalist_name):\n",
    "    '''\n",
    "    create density plot\n",
    "    '''\n",
    "    \n",
    "\n",
    "    if datalist_name == \"real\":\n",
    "        datalist = real_datalist\n",
    "    elif datalist_name == \"syn\":\n",
    "        datalist = syn_datalist\n",
    "\n",
    "    for missingtype in missingtypelist:\n",
    "        if missingtype == \"logistic\":\n",
    "            missing_rule = load_json_file(\"missing_rate.json\")\n",
    "        elif missingtype == \"diffuse\":\n",
    "            missing_rule = load_json_file(\"diffuse_ratio.json\")\n",
    "        elif missingtype == \"quantile\":\n",
    "            missing_rule = load_json_file(\"quantile_full.json\")\n",
    "\n",
    "        # load data and its mask\n",
    "        for dataname in datalist:\n",
    "            directory_path = f\"../datasets/{dataname}\"    \n",
    "            norm_values = np.load(f'{directory_path}/{dataname}_norm.npy')\n",
    "            \n",
    "            print(dataname)\n",
    "\n",
    "\n",
    "            for rule_name in missing_rule:\n",
    "                observed_masks = np.load(f'{directory_path}/{missingtype}/{rule_name}.npy')\n",
    "\n",
    "\n",
    "            return norm_values,observed_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(mask,complete,imputed):\n",
    "    missing_data_points = mask == 0\n",
    "\n",
    "    # Extracting the originally missing data from both complete and imputed data\n",
    "    original_values = complete[missing_data_points]\n",
    "    imputed_values = imputed[missing_data_points]\n",
    "\n",
    "    # Calculating RMSE\n",
    "    rmse = np.sqrt(np.mean((original_values - imputed_values) ** 2))\n",
    "\n",
    "    return rmse\n",
    "\n",
    "# def complete_computed_value(mask, complete, imputed):\n",
    "#     # Create an empty array with the same shape as 'complete' and 'imputed'\n",
    "#     computed = np.empty_like(complete)\n",
    "\n",
    "#     # Fill in the values\n",
    "#     computed[mask == 1] = complete[mask == 1]  # Use values from 'complete' where mask is 1\n",
    "#     computed[mask == 0] = imputed[mask == 0]   # Use values from 'imputed' where mask is 0\n",
    "\n",
    "#     return computed\n",
    "\n",
    "def complete_computed_value(mask, complete, imputed):\n",
    "    # Create an array filled with 'nan' with the same shape as 'complete' and 'imputed'\n",
    "    computed = np.full_like(complete, np.nan, dtype=float)\n",
    "\n",
    "    # Fill in the imputed values where mask is 0\n",
    "    computed[mask == 0] = imputed[mask == 0]\n",
    "\n",
    "    return computed\n",
    "\n",
    "# Example usage\n",
    "# mask, complete, and imputed should be numpy arrays of the same shape\n",
    "# complete_computed = complete_computed_value(mask, complete, imputed)\n",
    "\n",
    "\n",
    "def MAE(mask,complete,imputed):\n",
    "    missing_data_points = mask == 0\n",
    "\n",
    "    # Extracting the originally missing data from both complete and imputed data\n",
    "    original_values = complete[missing_data_points]\n",
    "    imputed_values = imputed[missing_data_points]\n",
    "\n",
    "    # Calculating RMSE\n",
    "    mae = np.mean(np.abs(original_values - imputed_values))\n",
    "\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_impute_data(missingtype,model_name,rule_name,dataname,fold,seed = 1):\n",
    "\n",
    "    train_impute = np.load(f'../impute/{missingtype}/{dataname}/{model_name}/{rule_name}_seed-{seed}_{fold}_train.npy')\n",
    "    test_impute = np.load(f'../impute/{missingtype}/{dataname}/{model_name}/{rule_name}_seed-{seed}_{fold}_test.npy')\n",
    "    return train_impute,test_impute\n",
    "\n",
    "def load_train_test(index_file,norm_values,observed_masks):  \n",
    "\n",
    "    train_index = index_file[\"train_index\"]\n",
    "    test_index = index_file[\"test_index\"]\n",
    "\n",
    "    train_values = norm_values[train_index,:]\n",
    "\n",
    "    train_masks = observed_masks[train_index,:]\n",
    "\n",
    "    test_values = norm_values[test_index,:]\n",
    "\n",
    "    test_masks = observed_masks[test_index,:]\n",
    "\n",
    "    return train_values,train_masks,test_values,test_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = real_datalist\n",
    "\n",
    "plot = True\n",
    "\n",
    "missingtypelist = [\"logistic\"]\n",
    "#model_list = [\"mean\",\"knn\",\"gain\",\"XGB\",\"mice\",\"mf\",\"notmiwae\",\"miwae\",\"missforest\",\"hyper\",\"tabcsdi\"]\n",
    "model_list = [\"knn\",\"hyper\",\"gain\",\"XGB\",\"mice\",\"mf\",\"missforest\",\"notmiwae\",\"miwae\",\"tabcsdi\",\"ot\"]\n",
    "for model_name in model_list:\n",
    "       cal_rmse_plot(missingtypelist,model_name,datalist)      \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_rmse_plot(missingtypelist,model_name,datalist):\n",
    "    quantilelist = [\"Q1_Q2_0.5\",\"Q1_Q4_0.5\",\"Q2_Q4_0.5\",\"Q1_Q2_1.0\",\"Q1_Q4_1.0\",\"Q2_Q4_1.0\"]\n",
    "    for missingtype in missingtypelist:\n",
    "        if missingtype == \"logistic\":\n",
    "            missing_rule = load_json_file(\"missing_rate.json\")\n",
    "        elif missingtype == \"diffuse\":\n",
    "            missing_rule = load_json_file(\"diffuse_ratio.json\")\n",
    "        elif missingtype == \"quantile\":\n",
    "            missing_rule = load_json_file(\"quantile_full.json\")\n",
    "\n",
    "        # load data and its mask\n",
    "        for dataname in tqdm(datalist):\n",
    "            directory_path = f\"../datasets/{dataname}\"    \n",
    "            norm_values = np.load(f'{directory_path}/{dataname}_norm.npy')\n",
    "            f = open(f'{directory_path}/split_index_cv_seed-{seed}_nfold-{nfold}.json')\n",
    "            index_file = json.load(f)\n",
    "            \n",
    "\n",
    "            for rule_name in tqdm(missing_rule):\n",
    "                if (rule_name in [\"0.8\"] and missingtype == \"diffuse\") or (rule_name in [\"0.5\",\"0.8\"] and missingtype == \"logistic\") or (rule_name in quantilelist and missingtype == \"quantile\"):\n",
    "                    observed_masks = np.load(f'{directory_path}/{missingtype}/{rule_name}.npy')\n",
    "\n",
    "                    for fold in index_file:\n",
    "                        index = index_file[fold]\n",
    "                        train_values,train_masks,test_values,test_masks = load_train_test(index,norm_values,observed_masks)\n",
    "                        try:\n",
    "                            impute_train,impute_test  = load_impute_data(missingtype,model_name,rule_name,dataname,fold)\n",
    "\n",
    "                            train_rmse = RMSE(train_masks,train_values,impute_train)\n",
    "                            train_mae = MAE(train_masks,train_values,impute_train)\n",
    "\n",
    "                            test_rmse = RMSE(test_masks,test_values,impute_test)\n",
    "                            test_mae = MAE(test_masks,test_values,impute_test)\n",
    "                    \n",
    "                            if train_rmse > 0 and plot:\n",
    "                                rmse = RMSE_columnwise(train_masks,train_values,impute_train)\n",
    "                                make_line_plot(train_values,impute_train,train_masks,title = f\"{dataname} {missingtype} {rule_name} {model_name} \",subtitle=rmse)\n",
    "\n",
    "                        except:\n",
    "                            pass\n",
    "                        break\n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_columnwise(mask, complete, imputed):\n",
    "\n",
    "\n",
    "    # Initializing an array to store RMSE for each column\n",
    "    rmse_per_column = np.zeros(complete.shape[1])\n",
    "\n",
    "    # Iterate over each column\n",
    "    for i in range(complete.shape[1]):\n",
    "        missing_data_points = mask[:, i] == 0\n",
    "        # Extracting the originally missing data from both complete and imputed data\n",
    "        original_values = complete[missing_data_points, i]\n",
    "        imputed_values = imputed[missing_data_points, i]\n",
    "\n",
    "        # Calculating RMSE for this column\n",
    "        rmse_per_column[i] = np.sqrt(np.mean((original_values - imputed_values) ** 2))\n",
    "\n",
    "    return np.nan_to_num(rmse_per_column, nan=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_line_plot(norm_value,impute,mask, title = None,subtitle = None):\n",
    "    indices = np.argsort(subtitle)[-4:]\n",
    "    \n",
    "    # Sorting the indices and converting to a list\n",
    "    sorted_indices = np.sort(indices).tolist()\n",
    "        # Create a 4x2 grid of subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    axes = axes.ravel()  # Flatten the 4x2 grid for easy iteration\n",
    "\n",
    "    impute_value = complete_computed_value(mask, norm_value, impute)\n",
    "    true_value = complete_computed_value(mask, norm_value, norm_value)\n",
    "    # nan_mask = np.where(mask == 0, np.nan, mask)\n",
    "    # masked_value_na = norm_value * nan_mask\n",
    "\n",
    "    for i in range(len(sorted_indices)):\n",
    "\n",
    "        \n",
    "        #norm_column = norm_value[:, sorted_indices[i]]\n",
    "        impute_column = impute_value[:, sorted_indices[i]]\n",
    "        #mask_column_na = masked_value_na[:, sorted_indices[i]]\n",
    "        true_column = true_value[:, sorted_indices[i]]\n",
    "        # Remove NaN values from both impute_column and true_column\n",
    "        valid_mask = ~np.isnan(impute_column) & ~np.isnan(true_column)\n",
    "        impute_column_clean = impute_column[valid_mask]\n",
    "        true_column_clean = true_column[valid_mask]\n",
    "\n",
    "        # Scatter plot for imputed vs. true values, using cleaned data\n",
    "        axes[i].scatter(impute_column_clean, true_column_clean, label='Imputed vs. True')\n",
    "        correlation_coefficient = np.corrcoef(impute_column_clean, true_column_clean)[0, 1]\n",
    "    \n",
    "        # Calculate and plot the best fit line, using cleaned data\n",
    "        if len(impute_column_clean) > 1:  # Ensure there's more than one data point for polyfit\n",
    "            coeffs = np.polyfit(impute_column_clean, true_column_clean, 1)\n",
    "            poly = np.poly1d(coeffs)\n",
    "            x_line = np.linspace(impute_column_clean.min(), impute_column_clean.max(), 100)\n",
    "            y_line = poly(x_line)\n",
    "            axes[i].plot(x_line, y_line, 'r-', label='Best Fit Line')\n",
    "    #     print(impute_column,true_column)\n",
    "        axes[i].plot([0, 1], [0, 1], 'gray',alpha = 0.5)  # Diagonal line\n",
    "                # Calculate and plot the best fit line\n",
    "\n",
    "        axes[i].set_ylim(0, 1)\n",
    "        axes[i].set_xlim(0, 1)\n",
    "        axes[i].set_xlabel('Imputed')\n",
    "        axes[i].set_yticks([0,0.2,0.4,0.6,0.8,1.0])\n",
    "        axes[i].set_xticks([0,0.2,0.4,0.6,0.8,1.0])\n",
    "        axes[i].set_ylabel('Ground  Truth')\n",
    "        axes[i].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        if subtitle[i]:\n",
    "            axes[i].set_title(f'Column {sorted_indices[i]+1} RMSE: {round(subtitle[sorted_indices][i],3)} Correlation: {round(correlation_coefficient,3)}')\n",
    "        else:\n",
    "            axes[i].set_title(f'Column {sorted_indices[i]+1}')\n",
    "        #axes[i].legend()\n",
    "\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "        # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../plot/correlation/{title}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
