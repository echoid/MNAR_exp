{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from scipy import optimize\n",
    "from data_loaders import *\n",
    "import missing_process.missing_method as missing_method\n",
    "from missing_process.block_rules import *\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Define the data\n",
    "X = np.array([[0, 0, 0], [1, 1, 1]])\n",
    "\n",
    "# Calculate the linear kernel\n",
    "kernel_matrix = linear_kernel(X, X)\n",
    "\n",
    "# Generate scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(kernel_matrix[:, 0], kernel_matrix[:, 1],label = \"kernal\", s=100)\n",
    "plt.scatter(X[:, 0], kernel_matrix[:, 1], cmap='viridis', s=100,label = \"original\")\n",
    "plt.colorbar(label='Linear Kernel Value')\n",
    "plt.title('Linear Kernel Matrix Scatter Plot')\n",
    "plt.xlabel('Sample 1')\n",
    "plt.ylabel('Sample 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def basis_expansion(X):\n",
    "\n",
    "    # Polynomial Features up to degree 2\n",
    "    poly = PolynomialFeatures(degree=3, include_bias=True)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "\n",
    "    # Circular functions: sine and cosine\n",
    "    X_sin = np.sin(X)\n",
    "    X_cos = np.cos(X)\n",
    "\n",
    "    # Logarithmic Transformation\n",
    "    log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "    X_log = log_transformer.fit_transform(X)\n",
    "\n",
    "    # Square Root Transformation\n",
    "    sqrt_transformer = FunctionTransformer(np.sqrt, validate=True)\n",
    "    X_sqrt = sqrt_transformer.fit_transform(X)\n",
    "\n",
    "    # Exponential Transformation\n",
    "    X_exp = np.exp(X)\n",
    "\n",
    "    # Gaussian Transformation\n",
    "    def gaussian_basis(X):\n",
    "        return np.exp(-X ** 2)\n",
    "\n",
    "    gaussian_transformer = FunctionTransformer(gaussian_basis, validate=True)\n",
    "    X_gaussian = gaussian_transformer.fit_transform(X)\n",
    "\n",
    "    # Sigmoid Transformation\n",
    "    def sigmoid_basis(X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "    sigmoid_transformer = FunctionTransformer(sigmoid_basis, validate=True)\n",
    "    X_sigmoid = sigmoid_transformer.fit_transform(X)\n",
    "\n",
    "    # Custom Basis Function sin+cos\n",
    "    def custom_basis(X):\n",
    "        return np.sin(X) + np.cos(X)\n",
    "\n",
    "    custom_transformer = FunctionTransformer(custom_basis, validate=True)\n",
    "    X_custom = custom_transformer.fit_transform(X)\n",
    "\n",
    "    # Concatenate original feature with expanded features\n",
    "    X_concatenated = np.hstack((X, X_poly, X_sin, X_cos, X_log, X_sqrt, X_exp, X_gaussian, X_sigmoid, X_custom))\n",
    "\n",
    "    # Check the shape of the concatenated data\n",
    "    return X_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_path(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        # If it doesn't exist, create it\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(sorted_values):\n",
    "        # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(len(sorted_values)), sorted_values)\n",
    "    plt.title('Sorted Values from Calith 7th Column')\n",
    "    plt.xlabel('Sorted Index')\n",
    "    plt.ylabel('Values')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def create_feature_expansion(missingtype = \"test_MNAR_1\",dataname = \"california\"):\n",
    "    save_name = dataname+\"_exp\"\n",
    "    if missingtype == \"test_MNAR_1\":    \n",
    "        missing_rule = load_json_file(f\"{missingtype}.json\")\n",
    "        missingtype = \"logistic\"\n",
    "        print(\"logistic\")\n",
    "    else:\n",
    "        missing_rule = load_json_file(f\"{missingtype}.json\")\n",
    "        missingtype = \"quantile\"\n",
    "\n",
    "\n",
    "    directory_path = f\"../datasets/{dataname}\" \n",
    "    save_path =  f\"../datasets/{save_name}\"\n",
    "    norm_values = np.load(f'{directory_path}/{dataname}_norm.npy')\n",
    "\n",
    "    target_column = norm_values[:, 6].reshape(-1, 1)\n",
    "    expanded_target = basis_expansion(target_column)\n",
    "\n",
    "    # Split array1 into two parts based on the insertion column\n",
    "    array_left = norm_values[:, :6]\n",
    "    array_right = norm_values[:, 6:]\n",
    "\n",
    "    # Insert array2 between the two parts\n",
    "    result = np.hstack((array_left, expanded_target, array_right))\n",
    "\n",
    "    check_path(save_path )\n",
    "    np.save(f'{save_path}/{save_name}_norm.npy', result)\n",
    "    #print(result.shape)\n",
    "\n",
    "    #return target_column\n",
    "\n",
    "    # for missingtype in missing_list.keys():\n",
    "    #     missing_rule = missing_list[missingtype]\n",
    "    #     #print(missingtype,missing_rule)\n",
    "\n",
    "    print(missing_rule)\n",
    "    for rule_name in missing_rule:\n",
    "        #print(rule_name)\n",
    "        rule = missing_rule[rule_name]\n",
    "        \n",
    "        observed_masks = np.load(f'{directory_path}/{missingtype}/{rule_name}.npy')\n",
    "        mask_left = observed_masks[:, :6]\n",
    "        mask_right = observed_masks[:, 6:]\n",
    "        target_mask = np.hstack([observed_masks[:, 6].reshape(-1, 1)] * expanded_target.shape[1])\n",
    "        result_mask = np.hstack((mask_left, target_mask, mask_right))\n",
    "        check_path(f'{save_path}/{missingtype}')\n",
    "        np.save(f'{save_path}/{missingtype}/{rule_name}.npy', result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic\n",
      "Directory '../datasets/california_exp' already exists.\n",
      "{'0.5': 0.5}\n",
      "Directory '../datasets/california_exp/logistic' created successfully.\n"
     ]
    }
   ],
   "source": [
    "create_feature_expansion(missingtype = \"test_MNAR_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 13)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
