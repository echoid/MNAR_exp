{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from scipy import optimize\n",
    "from data_loaders import *\n",
    "import missing_process.missing_method as missing_method\n",
    "from missing_process.block_rules import *\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def basis_expansion(X):\n",
    "\n",
    "    # Polynomial Features up to degree 2\n",
    "    poly = PolynomialFeatures(degree=3, include_bias=True)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "\n",
    "    # Circular functions: sine and cosine\n",
    "    X_sin = np.sin(X)\n",
    "    X_cos = np.cos(X)\n",
    "\n",
    "    # Logarithmic Transformation\n",
    "    log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "    X_log = log_transformer.fit_transform(X)\n",
    "\n",
    "    # Square Root Transformation\n",
    "    sqrt_transformer = FunctionTransformer(np.sqrt, validate=True)\n",
    "    X_sqrt = sqrt_transformer.fit_transform(X)\n",
    "\n",
    "    # Exponential Transformation\n",
    "    X_exp = np.exp(X)\n",
    "\n",
    "    # Gaussian Transformation\n",
    "    def gaussian_basis(X):\n",
    "        return np.exp(-X ** 2)\n",
    "\n",
    "    gaussian_transformer = FunctionTransformer(gaussian_basis, validate=True)\n",
    "    X_gaussian = gaussian_transformer.fit_transform(X)\n",
    "\n",
    "    # Sigmoid Transformation\n",
    "    def sigmoid_basis(X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "    sigmoid_transformer = FunctionTransformer(sigmoid_basis, validate=True)\n",
    "    X_sigmoid = sigmoid_transformer.fit_transform(X)\n",
    "\n",
    "    # Custom Basis Function sin+cos\n",
    "    def custom_basis(X):\n",
    "        return np.sin(X) + np.cos(X)\n",
    "\n",
    "    custom_transformer = FunctionTransformer(custom_basis, validate=True)\n",
    "    X_custom = custom_transformer.fit_transform(X)\n",
    "\n",
    "    # Concatenate original feature with expanded features\n",
    "    X_concatenated = np.hstack((X, X_poly, X_sin, X_cos, X_log, X_sqrt, X_exp, X_gaussian, X_sigmoid, X_custom))\n",
    "\n",
    "    # Check the shape of the concatenated data\n",
    "    return X_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_path(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        # If it doesn't exist, create it\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(sorted_values):\n",
    "        # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(len(sorted_values)), sorted_values)\n",
    "    plt.title('Sorted Values from Calith 7th Column')\n",
    "    plt.xlabel('Sorted Index')\n",
    "    plt.ylabel('Values')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def create_feature_expansion(missingtype = \"test_MNAR_1\",dataname = \"california\"):\n",
    "    save_name = dataname+\"_exp\"\n",
    "    if missingtype == \"test_MNAR_1\":    \n",
    "        missing_rule = load_json_file(f\"{missingtype}.json\")\n",
    "        missingtype = \"logistic\"\n",
    "        print(\"logistic\")\n",
    "    else:\n",
    "        missing_rule = load_json_file(f\"{missingtype}.json\")\n",
    "        missingtype = \"quantile\"\n",
    "\n",
    "\n",
    "    directory_path = f\"../datasets/{dataname}\" \n",
    "    save_path =  f\"../datasets/{save_name}\"\n",
    "    norm_values = np.load(f'{directory_path}/{dataname}_norm.npy')\n",
    "\n",
    "\n",
    "    array_left = []\n",
    "    array_right = []\n",
    "    for i in range(norm_values.shape[1]):\n",
    "        print(i)\n",
    "        if i != 6:\n",
    "\n",
    "            target_column = norm_values[:, i].reshape(-1, 1)\n",
    "            expanded_target = basis_expansion(target_column)\n",
    "\n",
    "            # # Split array1 into two parts based on the insertion column\n",
    "            # array_left = norm_values[:, :6]\n",
    "            # array_right = norm_values[:, 6:]\n",
    "\n",
    "            # Insert array2 between the two parts\n",
    "            result = np.hstack((target_column,expanded_target))\n",
    "            if i < 6:\n",
    "                array_left.append(result)\n",
    "            else:\n",
    "                array_right.append(result)\n",
    "\n",
    "    result = np.hstack((np.hstack(array_left),norm_values[:, 6].reshape(-1, 1),np.hstack(array_right)))\n",
    "\n",
    "    check_path(save_path)\n",
    "    np.save(f'{save_path}/{save_name}_norm.npy', result)\n",
    "    #print(result.shape)\n",
    "\n",
    "    #return target_column\n",
    "\n",
    "    # for missingtype in missing_list.keys():\n",
    "    #     missing_rule = missing_list[missingtype]\n",
    "    #     #print(missingtype,missing_rule)\n",
    "\n",
    "    print(missing_rule)\n",
    "    for rule_name in missing_rule:\n",
    "        #print(rule_name)\n",
    "        rule = missing_rule[rule_name]\n",
    "        \n",
    "        observed_masks = np.load(f'{directory_path}/{missingtype}/{rule_name}.npy')\n",
    "\n",
    "        mask_left = []\n",
    "        mask_right = []\n",
    "        for i in range(norm_values.shape[1]):\n",
    "            if i != 6:\n",
    "                expand_mask = np.hstack([observed_masks[:, i].reshape(-1, 1)] * (expanded_target.shape[1]+1))\n",
    "                if i < 6:\n",
    "                    mask_left.append(expand_mask)\n",
    "                else:\n",
    "                    mask_right.append(expand_mask)\n",
    "\n",
    "\n",
    "\n",
    "        result_mask = np.hstack((np.hstack(mask_left), observed_masks[:, 6].reshape(-1, 1), np.hstack(mask_right)))\n",
    "        check_path(f'{save_path}/{missingtype}')\n",
    "        print(result.shape)\n",
    "        print(result_mask.shape)\n",
    "        np.save(f'{save_path}/{missingtype}/{rule_name}.npy', result_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Directory '../datasets/california_exp' already exists.\n",
      "{'Q1_Q2_0.5': {'1': {'lower': 0.0, 'upper': 0.25, 'partial_missing': 0.5}, '2': {'lower': 0.25, 'upper': 0.5, 'partial_missing': 0.5}}, 'Q1_Q4_0.5': {'1': {'lower': 0.0, 'upper': 0.25, 'partial_missing': 0.5}, '2': {'lower': 0.75, 'upper': 1, 'partial_missing': 0.5}}, 'Q1_Q4_0.25': {'1': {'lower': 0.0, 'upper': 0.25, 'partial_missing': 0.75}, '2': {'lower': 0.75, 'upper': 1, 'partial_missing': 0.75}}, 'Q2_Q3_0.25': {'1': {'lower': 0.25, 'upper': 0.5, 'partial_missing': 0.75}, '2': {'lower': 0.5, 'upper': 0.75, 'partial_missing': 0.75}}, 'Q1_Q2_1.0': {'1': {'lower': 0.0, 'upper': 0.25, 'partial_missing': 0.0}, '2': {'lower': 0.25, 'upper': 0.5, 'partial_missing': 0.0}}}\n",
      "Directory '../datasets/california_exp/quantile' already exists.\n",
      "(20640, 99)\n",
      "(20640, 99)\n",
      "Directory '../datasets/california_exp/quantile' already exists.\n",
      "(20640, 99)\n",
      "(20640, 99)\n",
      "Directory '../datasets/california_exp/quantile' already exists.\n",
      "(20640, 99)\n",
      "(20640, 99)\n",
      "Directory '../datasets/california_exp/quantile' already exists.\n",
      "(20640, 99)\n",
      "(20640, 99)\n",
      "Directory '../datasets/california_exp/quantile' already exists.\n",
      "(20640, 99)\n",
      "(20640, 99)\n"
     ]
    }
   ],
   "source": [
    "create_feature_expansion(missingtype = \"test_MNAR_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Deakin\\\\MNAR_exp\\\\generation'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 13)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
