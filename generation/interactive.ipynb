{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "%matplotlib inline\n",
    "from scipy.io import arff\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import missing_process.missing_method as missing_method\n",
    "from missing_process.block_rules import *\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "\n",
    "#  https://cs.joensuu.fi/sipu/datasets/\n",
    "# dataset\n",
    "def MCAR(observed_values, missing_rate, masks):\n",
    "    # Check if missing_rate is between 0 and 1\n",
    "    if not 0 <= missing_rate <= 1:\n",
    "        raise ValueError(\"Missing rate must be between 0 and 1.\")\n",
    "    \n",
    "    n_samples, n_features = observed_values.shape\n",
    "    \n",
    "    new_mask = masks.copy()\n",
    "    # Copy observed_values to avoid altering the original data\n",
    "    data_with_missing = observed_values.copy()\n",
    "    \n",
    "\n",
    "    n_missing = int(n_samples * missing_rate)\n",
    "        \n",
    "        # Randomly choose indices for 'missing' data\n",
    "    missing_indices = np.random.choice(n_samples, n_missing, replace=False)\n",
    "        \n",
    "        # Set chosen indices to np.nan in the data and 0 in the masks\n",
    "    new_mask[missing_indices, 0] = 0\n",
    "    \n",
    "    return new_mask\n",
    "\n",
    "\n",
    "def MAR(observed_values, missing_rate,masks):\n",
    "    if observed_values.shape[1] < 2:\n",
    "        raise ValueError(\"The input array must have at least two columns for MAR.\")\n",
    "\n",
    "    n_samples = observed_values.shape[0]\n",
    "    \n",
    "    new_mask = masks.copy()\n",
    "\n",
    "    # Calculate the median of the second column\n",
    "    med = np.percentile(observed_values[:, 1],missing_rate*100)\n",
    "\n",
    "\n",
    "    # Identify indices where first column's value is larger than the median of the second column\n",
    "    missing_indices = np.where(observed_values[:, 1] < med)[0]\n",
    "\n",
    "    # Set these indices to 0 in the mask for the first column\n",
    "    new_mask[missing_indices, 0] = 0\n",
    "\n",
    "    return new_mask\n",
    "\n",
    "\n",
    "\n",
    "def MNAR(observed_values, missing_rate, masks):\n",
    "    if observed_values.shape[1] < 2:\n",
    "        raise ValueError(\"The input array must have at least two columns for MAR.\")\n",
    "\n",
    "    n_samples = observed_values.shape[0]\n",
    "    \n",
    "    new_mask = masks.copy()\n",
    "\n",
    "    # Calculate the median of the second column\n",
    "    med = np.percentile(observed_values[:, 0],missing_rate*100)\n",
    "\n",
    "    \n",
    "    # Identify indices where first column's value is larger than the median of the second column\n",
    "    missing_indices = np.where(observed_values[:, 0] < med)[0]\n",
    "    # Set these indices to 0 in the mask for the first column\n",
    "    new_mask[missing_indices, 0] = 0\n",
    "\n",
    "    return new_mask\n",
    "\n",
    "\n",
    "\n",
    "def simple_diffuse(observed_values, masks, up_percentile, obs_percentile):\n",
    "    # This is actually MAR\n",
    "    new_mask = masks.copy()\n",
    "\n",
    "    # Calculate the median of the second column\n",
    "    bound_1 = np.percentile(observed_values[:, 0], up_percentile)\n",
    "    bound_2 = np.percentile(observed_values[:, 1], obs_percentile)\n",
    "\n",
    "    # Identify indices where first column's value is larger than the median of the second column\n",
    "    missing_indices = np.where((observed_values[:, 0] < bound_1) & (observed_values[:, 1] < bound_2))[0]\n",
    "\n",
    "    # Set these indices to 0 in the mask for the first column\n",
    "    new_mask[missing_indices, 0] = 0\n",
    "\n",
    "    return new_mask\n",
    "\n",
    "\n",
    "def diffuse_mnar_single(data, up_percentile = 0.5, obs_percentile = 0.5):\n",
    "\n",
    "    mask = np.ones(data.shape)\n",
    "\n",
    "    miss_col = 0  # 随机选择缺失列的索引\n",
    "\n",
    "    obs_col = 1\n",
    "    \n",
    "    missvar_bounds = np.quantile(data[:, miss_col], up_percentile)\n",
    "    temp = data[:, miss_col] > missvar_bounds\n",
    "    \n",
    "    obsvar_bounds = np.quantile(data[:, obs_col], obs_percentile)\n",
    "    temp2 = data[:, miss_col] > obsvar_bounds\n",
    "\n",
    "    merged_temp = np.logical_or(temp, temp2).astype(int)\n",
    "    mask[:, miss_col] = merged_temp\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_rate(data):\n",
    "        # Create a mask to identify NaN values\n",
    "    nan_mask = np.isnan(data)\n",
    "\n",
    "    # Calculate the total number of NaN values in each column\n",
    "    nan_counts = np.sum(nan_mask, axis=0)\n",
    "\n",
    "    # Calculate the missing rate (percentage of NaN values) for each column\n",
    "    missing_rate = nan_counts / data.shape[0] * 100\n",
    "\n",
    "    print(\"Missing rate for each column:\")\n",
    "    for i, rate in enumerate(missing_rate):\n",
    "        print(f\"Column {i + 1}: {rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data):\n",
    "    if data == \"normal\":\n",
    "        orgin = np.random.randn(1000, 2)\n",
    "    elif data == \"4-clusters\":\n",
    "        orgin, y = make_blobs(n_samples=1000, centers=4, cluster_std=0.7, random_state=0)\n",
    "    elif data == \"negtive_correlated\":\n",
    "        mean = [0, 0]\n",
    "        std_devs = [1, 1]\n",
    "        correlation = -0.7\n",
    "        covariance = np.array([[std_devs[0]**2, correlation * std_devs[0] * std_devs[1]],\n",
    "                            [correlation * std_devs[0] * std_devs[1], std_devs[1]**2]])\n",
    "        orgin = np.random.multivariate_normal(mean, covariance, size=1000)\n",
    "    elif data == \"positive_correlated\":\n",
    "        mean = [0, 0]\n",
    "        std_devs = [1, 1]\n",
    "        correlation = 0.7\n",
    "        covariance = np.array([[std_devs[0]**2, correlation * std_devs[0] * std_devs[1]],\n",
    "                            [correlation * std_devs[0] * std_devs[1], std_devs[1]**2]])\n",
    "        orgin = np.random.multivariate_normal(mean, covariance, size=1000)\n",
    "\n",
    "    elif data == \"syn_donut\" or data == \"syn_spiral\":\n",
    "\n",
    "        data = arff.loadarff(f'../datasets/{data}/{data}.arff')\n",
    "        df = pd.DataFrame(data[0])\n",
    "        orgin = np.array(df[[\"a0\",\"a1\"]])\n",
    "\n",
    "\n",
    "    return orgin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dic(dataname_list):\n",
    "    full_d = {}\n",
    "\n",
    "    for data in dataname_list:\n",
    "        full_d[data] = {}\n",
    "\n",
    "        full_d[data][\"MCAR\"] = {}\n",
    "        full_d[data][\"MAR\"] = {}\n",
    "        full_d[data][\"MNAR\"] = {}\n",
    "        full_d[data][\"logistic\"] = {}\n",
    "        full_d[data][\"diffuse\"] = {}\n",
    "        full_d[data][\"diffuse_simple\"] = {}\n",
    "\n",
    "        orgin = create_dataset(data)\n",
    "        full_d[data][\"origin\"] = orgin\n",
    "\n",
    "            \n",
    "        observed_masks = ~np.isnan(orgin.astype(\"float32\"))\n",
    "        masks = observed_masks.copy().astype(\"float32\")\n",
    "\n",
    "        for i in [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "            # MCAR\n",
    "            observed_masks = ~np.isnan(orgin.astype(\"float32\"))\n",
    "            mcar_mask =  MCAR(orgin, i, masks)\n",
    "            nan_mask = np.where(mcar_mask == 0, np.nan, mcar_mask)\n",
    "            masked_value_na_MCAR = orgin * nan_mask\n",
    "            full_d[data][\"MCAR\"][i] = masked_value_na_MCAR\n",
    "\n",
    "\n",
    "            # MAR\n",
    "            observed_masks = ~np.isnan(orgin.astype(\"float32\"))\n",
    "            mar_mask =  MAR(orgin, i, masks)\n",
    "            nan_mask = np.where(mar_mask == 0, np.nan, mar_mask)\n",
    "            masked_value_na_MAR = orgin * nan_mask\n",
    "            full_d[data][\"MAR\"] [i] = masked_value_na_MAR\n",
    "\n",
    "\n",
    "            # logistic\n",
    "            observed_masks = ~np.isnan(orgin.astype(\"float32\"))\n",
    "            if i != 1:\n",
    "                logistic_mask =  missing_method.MNAR_mask_logistic(orgin,1-i,exclude_inputs=True)\n",
    "            else:\n",
    "                logistic_mask =  np.isnan(orgin.astype(\"float32\"))\n",
    "            nan_mask = np.where(logistic_mask == 0, np.nan, logistic_mask)\n",
    "            masked_value_na_logistic = orgin * nan_mask\n",
    "            full_d[data][\"logistic\"][i] = masked_value_na_logistic\n",
    "\n",
    "            # pure focus MNAR\n",
    "            observed_masks = ~np.isnan(orgin.astype(\"float32\"))\n",
    "            mask =  MNAR(orgin, i, masks)\n",
    "\n",
    "            nan_mask = np.where(mask == 0, np.nan, mask)\n",
    "            masked_value_na = orgin * nan_mask\n",
    "            full_d[data][\"MNAR\"] [i] = masked_value_na\n",
    "\n",
    "\n",
    "\n",
    "            # diffuse\n",
    "            observed_masks = ~np.isnan(orgin.astype(\"float32\"))\n",
    "            if i != 0:\n",
    "                diffuse_mask =  diffuse_mnar_single(orgin,i,i)\n",
    "                \n",
    "            else:\n",
    "                diffuse_mask =  ~np.isnan(orgin.astype(\"float32\"))\n",
    "            nan_mask = np.where(diffuse_mask == 0, np.nan, diffuse_mask)\n",
    "            masked_value_na_diffuse = orgin * nan_mask\n",
    "            full_d[data][\"diffuse\"][i] = masked_value_na_diffuse\n",
    "\n",
    "            \n",
    "            # simple diffuse\n",
    "\n",
    "            observed_masks = ~np.isnan(orgin.astype(\"float32\"))\n",
    "            if i != 0:\n",
    "                diffuse_mask = simple_diffuse(orgin, observed_masks,i*100,i*100)\n",
    "                \n",
    "            else:\n",
    "                diffuse_mask =  ~np.isnan(orgin.astype(\"float32\"))\n",
    "            nan_mask = np.where(diffuse_mask == 0, np.nan, diffuse_mask)\n",
    "            masked_value_na_diffuse = orgin * nan_mask\n",
    "            full_d[data][\"diffuse_simple\"][i] = masked_value_na_diffuse\n",
    "\n",
    "\n",
    "    return full_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(parameter = 0.5,mechanism = [\"MCAR\",\"MAR\",\n",
    "                                           \"MNAR-Focus(percentile)\",\n",
    "                                           \"MNAR-Focus(logistic)\",\n",
    "                                           \"MNAR-Diffuse\",\"MNAR-Diffuse(Simple)\",\n",
    "                                           ], \n",
    "              dataset = [\"normal\",\"4-clusters\",\"negtive_correlated\",\n",
    "                         \"positive_correlated\",\"syn_spiral\"],\n",
    "                ):\n",
    "        # Create a figure and axes\n",
    "    \n",
    "    if mechanism == \"MCAR\":\n",
    "        masked_value_na = full_d[dataset][\"MCAR\"][parameter]\n",
    "    elif mechanism == \"MAR\":\n",
    "        masked_value_na = full_d[dataset][\"MAR\"][parameter]\n",
    "    elif mechanism == \"MNAR-Focus(logistic)\":\n",
    "        masked_value_na = full_d[dataset][\"logistic\"][parameter]\n",
    "    elif mechanism == \"MNAR-Focus(percentile)\":\n",
    "        masked_value_na = full_d[dataset][\"MNAR\"][parameter]\n",
    "    elif mechanism == \"MNAR-Diffuse\":\n",
    "        masked_value_na = full_d[dataset][\"diffuse\"][parameter]\n",
    "    elif mechanism == \"MNAR-Diffuse(Simple)\":\n",
    "        masked_value_na = full_d[dataset][\"diffuse_simple\"][parameter]\n",
    "        \n",
    "    orgin = full_d[dataset][\"origin\"]\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    # Scatter plot\n",
    "    ax.scatter(masked_value_na[:, 0], masked_value_na[:, 1], s=10,label = \"Data After Missing\",marker=\"o\",alpha=1, c=\"red\")\n",
    "    ax.scatter(orgin[:, 0], orgin[:, 1], s=10,label = \"Complete Data\",marker=\".\")\n",
    "    ax.set_title(f'{mechanism}')\n",
    "    ax.set_xlabel('Missing Column')\n",
    "    ax.set_ylabel('Observed Column')\n",
    "    ax.legend(loc = 1)\n",
    "    if dataset == \"normal\":\n",
    "        ax.set_xlim(-3,3)\n",
    "        ax.set_ylim(-3,3)\n",
    "    elif dataset == \"4-clusters\":\n",
    "        ax.set_xlim(-5,4)\n",
    "        ax.set_ylim(-5,10)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926202539bc94374a490cdcb68b9561d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='parameter', max=1.0), Dropdown(description='mechanis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.make_plot(parameter=0.5, mechanism=['MCAR', 'MAR', 'MNAR-Focus(percentile)', 'MNAR-Focus(logistic)', 'MNAR-Diffuse', 'MNAR-Diffuse(Simple)'], dataset=['normal', '4-clusters', 'negtive_correlated', 'positive_correlated', 'syn_spiral'])>"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_d = make_dic([\"normal\",\"4-clusters\",\"negtive_correlated\",\"positive_correlated\",\"syn_spiral\"])\n",
    "ipywidgets.interact(make_plot,parameter= (0,1,0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 515., 1000.])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
