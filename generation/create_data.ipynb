{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from scipy import optimize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from data_loaders import *\n",
    "import missing_process.missing_method as missing_method\n",
    "from missing_process.block_rules import *\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_datalist = [\"banknote\",\"concrete_compression\",\n",
    "            \"wine_quality_white\",\"wine_quality_red\",\n",
    "            \"california\",\"climate_model_crashes\",\n",
    "            \"connectionist_bench_sonar\",\"qsar_biodegradation\",\n",
    "            \"yeast\",\"yacht_hydrodynamics\"\n",
    "            ]\n",
    "\n",
    "syn_datalist = [\"syn1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataname,observed_values = None):\n",
    "    \"\"\"\"\n",
    "    Apply missing rules\n",
    "    Nosplit: False-> using trainset, True->using full dataset\n",
    "    \"\"\"\n",
    "    directory_path = f\"datasets/{dataname}\"\n",
    "\n",
    "    if dataname in real_datalist:\n",
    "        \n",
    "        data = dataset_loader(dataname)\n",
    "        observed_values = data[\"data\"].astype(\"float32\")\n",
    "        os.listdir(directory_path)\n",
    "        np.save(f'{directory_path}/{dataname}.npy', observed_values)\n",
    "    elif dataname in syn_datalist:\n",
    "        observed_values = np.load(f'{directory_path}/{dataname}.npy')\n",
    "    elif dataname not in syn_datalist+real_datalist and observed_values is not None:\n",
    "        if os.path.exists(directory_path):\n",
    "            np.save(f'{directory_path}/{dataname}.npy', observed_values.astype(\"float32\"))\n",
    "            print(f\"Directory '{directory_path}' created successfully.\")\n",
    "        else:\n",
    "            os.makedirs(directory_path, exist_ok=True)\n",
    "            np.save(f'{directory_path}/{dataname}.npy', observed_values)\n",
    "            print(f\"Create directory '{directory_path}'.\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid Data\")\n",
    "        \n",
    "    return observed_values    \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def min_max_scaler(observed_values):\n",
    "    min_val = np.min(observed_values,axis=0)\n",
    "    max_val = np.max(observed_values,axis=0)\n",
    "    \n",
    "    scaled_array = (observed_values - min_val + 1e-10)  / (max_val - min_val + 1e-10)\n",
    "    \n",
    "    return np.round(scaled_array,10)\n",
    "\n",
    "\n",
    "def sensitivity_check(observed_values):\n",
    "\n",
    "\n",
    "    min_values = np.min(observed_values, axis=0)\n",
    "    max_values = np.max(observed_values, axis=0)\n",
    "\n",
    "    min_check = np.any(min_values > 1) or np.any(min_values < 0)\n",
    "    max_check = np.any(max_values > 1) or np.any(max_values < 0)\n",
    "    \n",
    "    if min_check or max_check:\n",
    "        print(\"Test did not pass: Min or Max values out of range\")\n",
    "    else:\n",
    "        print(\"Test passed: Min and Max values are within range\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_split_index(scaled_data,directory_path,seed = 1,nfold = 5):\n",
    "    indlist = np.arange(len(scaled_data))\n",
    "\n",
    "    np.random.seed(seed + 1)\n",
    "    np.random.shuffle(indlist)\n",
    "\n",
    "    tmp_ratio = 1 / nfold\n",
    "    start = (int)((nfold - 1) * len(scaled_data) * tmp_ratio)\n",
    "\n",
    "    end = (int)(nfold * len(scaled_data) * tmp_ratio)\n",
    "\n",
    "    test_index = indlist[start:end]\n",
    "    remain_index = np.delete(indlist, np.arange(start, end))\n",
    "\n",
    "    np.random.shuffle(remain_index)\n",
    "\n",
    "    # Modify here to change train,valid ratio\n",
    "    num_train = (int)(len(remain_index) * 0.9)\n",
    "    train_index = remain_index[:num_train]\n",
    "    valid_index = remain_index[num_train:]\n",
    "\n",
    "    save_index = {}\n",
    "    save_index[\"test_index\"] = test_index.astype(np.int64).tolist()\n",
    "    save_index[\"train_index\"] = train_index.astype(np.int64).tolist()\n",
    "    save_index[\"valid_index\"] = valid_index.astype(np.int64).tolist()\n",
    "    with open(f\"{directory_path}/split_index_seed-{seed}.json\", 'w') as file:\n",
    "        json.dump(save_index, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: Min and Max values are within range\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "nfold = 5\n",
    "\n",
    "\n",
    "for data_name in real_datalist:\n",
    "\n",
    "    directory_path = f\"datasets/{data_name}\"\n",
    "    observed_values = get_data(data_name)\n",
    "    \n",
    "    scaled_data = min_max_scaler(observed_values)\n",
    "    sensitivity_check(scaled_data)\n",
    "\n",
    "    np.save(f'{directory_path}/{data_name}_norm.npy', scaled_data)\n",
    "\n",
    "    save_split_index(scaled_data,directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syn 1\n",
    "\n",
    " - normal distributions for the first two columns\n",
    " - discrete distributions for columns 3-4 with variable outcomes\n",
    " - skewed distributions for columns 5-6\n",
    " - mixed normal distributions for columns 7-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimensions of the 2D array\n",
    "rows = 1000\n",
    "cols = 8  # Set to 8 columns\n",
    "np.random.seed(1) \n",
    "# Create an empty array to store the data\n",
    "syn1 = np.empty((rows, cols))\n",
    "\n",
    "# Create normal distributions for the first two columns\n",
    "for i in range(2):\n",
    "    mean = np.random.uniform(-10, 10)\n",
    "    std_dev = np.random.uniform(0.1, 5)\n",
    "    syn1[:, i] = np.random.normal(mean, std_dev, size=rows)\n",
    "\n",
    "# Create discrete distributions for columns 3-4 with variable outcomes\n",
    "for i in range(2, 4):\n",
    "    if i == 2:\n",
    "        outcomes = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5]\n",
    "    else:\n",
    "        outcomes = [1,1,1, 2, 2, 3, 3, 3, 4,]\n",
    "    syn1[:, i] = np.random.choice(outcomes, size=rows)\n",
    "\n",
    "# Create skewed distributions for columns 5-6\n",
    "for i in range(4, 6):\n",
    "    skewness = np.random.uniform(-100, 100)\n",
    "    syn1[:, i] = stats.skewnorm.rvs(skewness, size=rows)\n",
    "\n",
    "# Create mixed normal distributions for columns 7-8\n",
    "for i in range(6, 8):\n",
    "    if i % 2 == 0:\n",
    "        # Create a normal distribution with mode at 2\n",
    "        normal_dist1 = np.random.normal(2, 1, size=rows)\n",
    "        normal_dist2 = np.random.normal(6, 0.5, size=rows)  # Additional normal distribution\n",
    "        syn1[:, i] = np.random.choice(np.concatenate([normal_dist1, normal_dist2]), size=rows)\n",
    "    else:\n",
    "        # Create a normal distribution with mode at -2\n",
    "        normal_dist1 = np.random.normal(-2, 3, size=rows)\n",
    "        normal_dist2 = np.random.normal(-6, 0.5, size=rows)  # Additional normal distribution\n",
    "        syn1[:, i] = np.random.choice(np.concatenate([normal_dist1, normal_dist2]), size=rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
